{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projekt2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1UeLSJCelka"
      },
      "source": [
        "*   Damian Jurkiewicz - jurkiewicz@student.agh.edu.pl\n",
        "*   Daniel Klarenbach - klarenbach@student.agh.edu.pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fev9VvdpWACY"
      },
      "source": [
        "# Zadanie 1 - Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMedf663d9bc"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M64zwipeC9q"
      },
      "source": [
        "SZ=28\n",
        "affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR\n",
        "\n",
        "def deskew(img):\n",
        "    m = cv2.moments(img)\n",
        "    if abs(m['mu02']) < 1e-2:\n",
        "        return img.copy()\n",
        "    skew = m['mu11']/m['mu02']\n",
        "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
        "    img = cv2.warpAffine(img,M,(SZ, SZ),flags=affine_flags)\n",
        "    return img"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxjTnxgeEbt"
      },
      "source": [
        "def showOpencvImage(image, isGray=False):\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.show()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqn5M0VMeGCT"
      },
      "source": [
        "def openCVHOG(im):\n",
        "    winSize = (20,20)\n",
        "    blockSize = (10,10)\n",
        "    blockStride = (5,5)\n",
        "    cellSize = (10,10)\n",
        "    nbins = 9\n",
        "    derivAperture = 1\n",
        "    winSigma = -1.\n",
        "    histogramNormType = 0\n",
        "    L2HysThreshold = 0.2\n",
        "    gammaCorrection = 1\n",
        "    nlevels = 64\n",
        "    signedGradients = True\n",
        "\n",
        "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)\n",
        "    descriptor = np.ravel(hog.compute(im))\n",
        "    \n",
        "    return descriptor"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3_S3cgceKjq"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def print_report(test_y,pred_y):\n",
        "    mask = pred_y==test_y\n",
        "    correct = np.count_nonzero(mask)\n",
        "    print(correct*100.0/pred_y.size)\n",
        "\n",
        "    cm = confusion_matrix(test_y, pred_y)\n",
        "    print(cm)\n",
        "    print(classification_report(test_y, pred_y)) "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjvpz_n8eYaJ"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4Y_17C3xOJW"
      },
      "source": [
        "# Zmniejszony zbiór testowy - finalnie pominąć \n",
        "\n",
        "train_images = train_images[0:600]\n",
        "train_labels = train_labels[0:600]\n",
        "test_images = test_images[0:100]\n",
        "test_labels = test_labels[0:100]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgQoyq-g8vP6"
      },
      "source": [
        "train_raw = train_images.reshape(len(train_images), 28 * 28)\n",
        "test_raw = test_images.reshape(len(test_images), 28 * 28)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XbYUjNUWUvJ"
      },
      "source": [
        "Przygotowanie zbiorów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JTqkZGLw_Dv"
      },
      "source": [
        "train_deskewed =  np.float32([deskew(im) for im in train_raw])\n",
        "test_deskewed =  np.float32([deskew(im) for im in test_raw])\n",
        "\n",
        "train_deskewed = np.asarray(train_deskewed).reshape(-1,28*28)\n",
        "test_deskewed = np.asarray(test_deskewed).reshape(-1,28*28)\n",
        "\n",
        "# train_deskewed\n",
        "# test_deskewed"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTHJiaDCxGTx"
      },
      "source": [
        "hogdata_train = [openCVHOG(im) for im in train_images]\n",
        "hogdata_train = np.float32(hogdata_train).reshape(-1,81)\n",
        "\n",
        "hogdata_test = [openCVHOG(im) for im in test_images]\n",
        "hogdata_test = np.float32(hogdata_test).reshape(-1,81)\n",
        "\n",
        "# hogdata_train\n",
        "# hogdata_test"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k6rf9gmxGuh"
      },
      "source": [
        "deskewed_hogdata_train = [openCVHOG(deskew(im)) for im in train_images]\n",
        "deskewed_hogdata_train = np.float32(deskewed_hogdata_train).reshape(-1,81)\n",
        "\n",
        "deskewed_hogdata_test = [openCVHOG(deskew(im)) for im in test_images]\n",
        "deskewed_hogdata_test = np.float32(deskewed_hogdata_test).reshape(-1,81)\n",
        "\n",
        "# deskewed_hogdata_train\n",
        "# deskewed_hogdata_test"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFW1EdyKxIZX"
      },
      "source": [
        "deskewed_reshape_train = [deskew(im).flatten() for im in train_images]\n",
        "deskewed_reshape_train = np.float32(deskewed_reshape_train)\n",
        "deskewed_reshape_train = np.asarray(deskewed_reshape_train)\n",
        "\n",
        "deskewed_reshape_test = [deskew(im).flatten() for im in test_images]\n",
        "deskewed_reshape_test = np.float32(deskewed_reshape_test)\n",
        "\n",
        "# deskewed_reshape_train\n",
        "# deskewed_reshape_test"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-13tQcsxLnZ"
      },
      "source": [
        "deskewed_reshape_train_copy = [deskew(im).flatten() for im in train_images]\n",
        "deskewed_reshape_shuffle_train = np.float32(deskewed_reshape_train_copy)\n",
        "np.random.shuffle(deskewed_reshape_shuffle_train)\n",
        "\n",
        "deskewed_reshape_test = [deskew(im).flatten() for im in test_images]\n",
        "deskewed_reshape_shuffle_test = np.float32(deskewed_reshape_test)\n",
        "np.random.shuffle(deskewed_reshape_shuffle_test)\n",
        "\n",
        "# deskewed_reshape_shuffle_train\n",
        "# deskewed_reshape_shuffle_test"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiC4apvug3CA"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def grid_search_svc(train_X,train_y,test_X,test_y):\n",
        "  parameters = [{\n",
        "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
        "    \"C\": [0.1,1, 10, 100, 1000], \n",
        "    \"gamma\": [0.1, 0.01, 0.001, 0.0001]\n",
        "  }]\n",
        "  model = SVC()\n",
        "\n",
        "  grid_search = GridSearchCV(model, parameters, scoring='accuracy', cv=5)\n",
        "  grid_search.fit(train_X, train_y)\n",
        "  clf = grid_search.best_estimator_\n",
        "  print(\"Best classifier: \", clf)\n",
        "\n",
        "  params = grid_search.best_params_\n",
        "  print(\"Chosing params: \", params)\n",
        "\n",
        "  pred_y = clf.predict(test_X)\n",
        "  print_report(test_y,pred_y)\n",
        "\n",
        "def grid_search_rfn(train_X,train_y,test_X,test_y):\n",
        "  parameters = [{\n",
        "    \"max_depth\": [10, 15, 20],\n",
        "    \"n_estimators\": [50, 100, 120],\n",
        "    \"max_features\": [40, 60, 80]\n",
        "  }]\n",
        "  model = RandomForestClassifier()\n",
        "\n",
        "  grid_search = GridSearchCV(model, parameters, scoring='accuracy', cv=5)\n",
        "  grid_search.fit(train_X, train_y)\n",
        "  clf = grid_search.best_estimator_\n",
        "  print(\"Best classifier: \", clf)\n",
        "\n",
        "  params = grid_search.best_params_\n",
        "  print(\"Chosing params: \", params)\n",
        "\n",
        "  pred_y = clf.predict(test_X)\n",
        "  print_report(test_y,pred_y)\n",
        "\n",
        "def create_model(input_shape):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(512, activation='relu', input_shape=(input_shape,)))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def grid_search_nn(train_X,train_y,test_X,test_y,input_shape):\n",
        "  train_X = train_X.reshape((len(train_X), input_shape))\n",
        "  test_X = test_X.reshape((len(test_X), input_shape))\n",
        "  train_X = train_X.astype('float32') / 255\n",
        "  test_X = test_X.astype('float32') / 255\n",
        "  encoded_train_y = to_categorical(train_y)\n",
        "  encoded_test_y = to_categorical(test_y)\n",
        "\n",
        "  parameters = [{'input_shape':[input_shape],'batch_size': [10, 20, 40, 60, 80, 100], 'epochs': [10, 50, 100] }]\n",
        "  model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "  grid_search = GridSearchCV(model, parameters, n_jobs=-1, cv=5)\n",
        "  grid_search.fit(train_X, encoded_train_y)\n",
        "  clf = create_model(input_shape)\n",
        "  clf.fit(train_X, encoded_train_y, epochs=grid_search.best_params_['epochs'], batch_size=grid_search.best_params_['batch_size'])\n",
        "  print(\"Best classifier: \", clf)\n",
        "\n",
        "  params = grid_search.best_params_\n",
        "  print(\"Chosing params: \", params)\n",
        "\n",
        "  pred_probabilities = clf.predict(test_X)\n",
        "  pred_y = np.argmax(pred_probabilities,-1)\n",
        "  print_report(test_y,pred_y)\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-Eu2u8DxqRh"
      },
      "source": [
        "# Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t436mtfsxvv5"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOOS6Toe1TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb3e877-522d-4405-d2e9-d31586497154"
      },
      "source": [
        "# A\n",
        "grid_search_svc(deskewed_hogdata_train, train_labels, deskewed_hogdata_test, test_labels)\n",
        "\n",
        "# B\n",
        "grid_search_svc(hogdata_train, train_labels, hogdata_test, test_labels)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier:  SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='sigmoid',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Chosing params:  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
            "97.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  7  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 13  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  0  0  0  0  1 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      1.00      1.00         7\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.87      0.93        15\n",
            "           8       0.67      1.00      0.80         2\n",
            "           9       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.95      0.98      0.96       100\n",
            "weighted avg       0.97      0.97      0.97       100\n",
            "\n",
            "Best classifier:  SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Chosing params:  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
            "96.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  6  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 14  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  0  0  0  1  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      0.86      0.92         7\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.93      0.93      0.93        15\n",
            "           8       0.67      1.00      0.80         2\n",
            "           9       1.00      0.82      0.90        11\n",
            "\n",
            "    accuracy                           0.96       100\n",
            "   macro avg       0.94      0.96      0.95       100\n",
            "weighted avg       0.97      0.96      0.96       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su1XGmMUx1pi"
      },
      "source": [
        "RandomForest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNzTqbtjy3T1",
        "outputId": "7fc4e775-9ea2-4294-88b2-2c3e7e5dc03a"
      },
      "source": [
        "# A\n",
        "grid_search_rfn(deskewed_hogdata_train, train_labels, deskewed_hogdata_test, test_labels)\n",
        "\n",
        "# B\n",
        "grid_search_rfn(hogdata_train, train_labels, hogdata_test, test_labels)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=20, max_features=40,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Chosing params:  {'max_depth': 20, 'max_features': 40, 'n_estimators': 120}\n",
            "96.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  7  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  7  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 14  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  1]\n",
            " [ 1  0  0  0  0  0  0  0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.88      0.93         8\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      1.00      1.00         7\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.93      0.97        15\n",
            "           8       1.00      0.50      0.67         2\n",
            "           9       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.96       100\n",
            "   macro avg       0.96      0.92      0.93       100\n",
            "weighted avg       0.96      0.96      0.96       100\n",
            "\n",
            "Best classifier:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=15, max_features=40,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Chosing params:  {'max_depth': 15, 'max_features': 40, 'n_estimators': 120}\n",
            "85.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  7  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  5  0  0  1  0]\n",
            " [ 0  0  0  0  1  0  9  0  0  0]\n",
            " [ 0  0  1  2  0  0  0 12  0  0]\n",
            " [ 0  0  0  0  1  1  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  1  3  6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.88      0.88      0.88         8\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       0.82      1.00      0.90        14\n",
            "           5       0.71      0.71      0.71         7\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       0.92      0.80      0.86        15\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       1.00      0.55      0.71        11\n",
            "\n",
            "    accuracy                           0.85       100\n",
            "   macro avg       0.80      0.77      0.78       100\n",
            "weighted avg       0.88      0.85      0.85       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXTl047lx4xY"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q-6avbCy4IH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4249c840-f911-40a9-da85-b6032c33863e"
      },
      "source": [
        "# A\n",
        "grid_search_nn(deskewed_hogdata_train, train_labels, deskewed_hogdata_test, test_labels, 81)\n",
        "\n",
        "# B\n",
        "grid_search_nn(hogdata_train, train_labels, hogdata_test, test_labels,81)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.3016 - accuracy: 0.1029\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2948 - accuracy: 0.1319\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2857 - accuracy: 0.1229\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2810 - accuracy: 0.1268\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2784 - accuracy: 0.1100\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2613 - accuracy: 0.1327\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2587 - accuracy: 0.1510\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2416 - accuracy: 0.1516\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2025 - accuracy: 0.2395\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1892 - accuracy: 0.2298\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1707 - accuracy: 0.2451\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1276 - accuracy: 0.2856\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1082 - accuracy: 0.3411\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0858 - accuracy: 0.3369\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0298 - accuracy: 0.3696\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0020 - accuracy: 0.3576\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9828 - accuracy: 0.3510\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9211 - accuracy: 0.4088\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8611 - accuracy: 0.4652\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8420 - accuracy: 0.4686\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8359 - accuracy: 0.5152\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8165 - accuracy: 0.5204\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7686 - accuracy: 0.5503\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7733 - accuracy: 0.5376\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7201 - accuracy: 0.5506\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6850 - accuracy: 0.5764\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6357 - accuracy: 0.5556\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6526 - accuracy: 0.5627\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6463 - accuracy: 0.5814\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5792 - accuracy: 0.5907\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5663 - accuracy: 0.6098\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5376 - accuracy: 0.5876\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5343 - accuracy: 0.6502\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5272 - accuracy: 0.6305\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4595 - accuracy: 0.6267\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4758 - accuracy: 0.6279\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4511 - accuracy: 0.6276\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3963 - accuracy: 0.6521\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3930 - accuracy: 0.6691\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3462 - accuracy: 0.6444\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3933 - accuracy: 0.6604\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3387 - accuracy: 0.6755\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2982 - accuracy: 0.6910\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2968 - accuracy: 0.6856\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3239 - accuracy: 0.6953\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2792 - accuracy: 0.6808\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2546 - accuracy: 0.7236\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2314 - accuracy: 0.7027\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2216 - accuracy: 0.7304\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1626 - accuracy: 0.7422\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1772 - accuracy: 0.7517\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1521 - accuracy: 0.7367\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1265 - accuracy: 0.7555\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1535 - accuracy: 0.7365\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1407 - accuracy: 0.7347\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0851 - accuracy: 0.7713\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1093 - accuracy: 0.7426\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0363 - accuracy: 0.8044\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0825 - accuracy: 0.7571\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0603 - accuracy: 0.7698\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0108 - accuracy: 0.7613\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0004 - accuracy: 0.7994\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0085 - accuracy: 0.7713\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9877 - accuracy: 0.7881\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9831 - accuracy: 0.7845\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9712 - accuracy: 0.8151\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9699 - accuracy: 0.7814\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9454 - accuracy: 0.8064\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9482 - accuracy: 0.7620\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9043 - accuracy: 0.7949\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8739 - accuracy: 0.7988\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8876 - accuracy: 0.8201\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8895 - accuracy: 0.7702\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8498 - accuracy: 0.8364\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8591 - accuracy: 0.8074\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8131 - accuracy: 0.8106\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8262 - accuracy: 0.8215\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8057 - accuracy: 0.8219\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8269 - accuracy: 0.8040\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7982 - accuracy: 0.8267\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8013 - accuracy: 0.8145\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7909 - accuracy: 0.8171\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7875 - accuracy: 0.8271\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7616 - accuracy: 0.8559\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7450 - accuracy: 0.8221\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.8276\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7422 - accuracy: 0.8310\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.8374\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.8391\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 0.8216\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7138 - accuracy: 0.8301\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.8497\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.8416\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.8213\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.8423\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.8332\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.8606\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.8504\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.8592\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.8432\n",
            "Best classifier:  <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f73fc696b90>\n",
            "Chosing params:  {'batch_size': 10, 'epochs': 100, 'input_shape': 81}\n",
            "89.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  7  0  0  0  0  1  0  0]\n",
            " [ 0  0  2  9  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  5  0  0  0  2]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  1  1  0  0  0 12  0  1]\n",
            " [ 0  0  0  0  0  1  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  1  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.70      0.88      0.78         8\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       0.83      0.71      0.77         7\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.86      0.80      0.83        15\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.71      0.91      0.80        11\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.80      0.81      0.80       100\n",
            "weighted avg       0.88      0.89      0.88       100\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 1ms/step - loss: 2.3012 - accuracy: 0.1464\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2942 - accuracy: 0.1220\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2917 - accuracy: 0.1308\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2870 - accuracy: 0.1217\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2804 - accuracy: 0.1391\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2758 - accuracy: 0.1274\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2650 - accuracy: 0.1306\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2454 - accuracy: 0.1435\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2416 - accuracy: 0.1484\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2092 - accuracy: 0.2111\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1890 - accuracy: 0.2315\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1886 - accuracy: 0.2666\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1527 - accuracy: 0.2776\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1130 - accuracy: 0.2872\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0950 - accuracy: 0.2899\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0598 - accuracy: 0.3535\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0578 - accuracy: 0.3193\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0290 - accuracy: 0.3607\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0081 - accuracy: 0.3994\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9768 - accuracy: 0.4399\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9523 - accuracy: 0.4132\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9380 - accuracy: 0.5099\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8817 - accuracy: 0.4641\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8639 - accuracy: 0.5248\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7940 - accuracy: 0.5683\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7862 - accuracy: 0.5438\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7875 - accuracy: 0.5710\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7399 - accuracy: 0.5597\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6981 - accuracy: 0.5474\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.7090 - accuracy: 0.5691\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6877 - accuracy: 0.6003\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6332 - accuracy: 0.6079\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6724 - accuracy: 0.5732\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5853 - accuracy: 0.6756\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5571 - accuracy: 0.6041\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5871 - accuracy: 0.6143\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5503 - accuracy: 0.6256\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4996 - accuracy: 0.6788\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4950 - accuracy: 0.6442\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4712 - accuracy: 0.6585\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4429 - accuracy: 0.6886\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4369 - accuracy: 0.6672\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4359 - accuracy: 0.6709\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3965 - accuracy: 0.6872\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4300 - accuracy: 0.6619\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3612 - accuracy: 0.6713\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3742 - accuracy: 0.6830\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3046 - accuracy: 0.6976\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3824 - accuracy: 0.6603\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3724 - accuracy: 0.6735\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3102 - accuracy: 0.7140\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2670 - accuracy: 0.6894\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2732 - accuracy: 0.7231\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2302 - accuracy: 0.7190\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2427 - accuracy: 0.7128\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2362 - accuracy: 0.7463\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2330 - accuracy: 0.6847\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1949 - accuracy: 0.7510\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1862 - accuracy: 0.7226\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2159 - accuracy: 0.7221\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1526 - accuracy: 0.7250\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1440 - accuracy: 0.7573\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1140 - accuracy: 0.7766\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0840 - accuracy: 0.7644\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0904 - accuracy: 0.7530\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0714 - accuracy: 0.7697\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0717 - accuracy: 0.7751\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0327 - accuracy: 0.7680\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.8131\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0391 - accuracy: 0.7851\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0345 - accuracy: 0.7583\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9727 - accuracy: 0.7930\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9517 - accuracy: 0.7995\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0048 - accuracy: 0.8066\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9278 - accuracy: 0.7920\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9655 - accuracy: 0.7824\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.7934\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.7799\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8996 - accuracy: 0.7762\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.7990\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8961 - accuracy: 0.8050\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8549 - accuracy: 0.8233\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8972 - accuracy: 0.8063\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9086 - accuracy: 0.7751\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8606 - accuracy: 0.7988\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8444 - accuracy: 0.8049\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8456 - accuracy: 0.7986\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.8037\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8257 - accuracy: 0.8132\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7734 - accuracy: 0.8409\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.7704\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8214 - accuracy: 0.8051\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7712 - accuracy: 0.8383\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7858 - accuracy: 0.8160\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7601 - accuracy: 0.8112\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.8125\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7361 - accuracy: 0.8291\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7851 - accuracy: 0.7878\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.8300\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.8367\n",
            "Best classifier:  <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f73f8564a10>\n",
            "Chosing params:  {'batch_size': 10, 'epochs': 100, 'input_shape': 81}\n",
            "79.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 13  0  0  0  0  0  0  1  0]\n",
            " [ 0  1  6  0  0  0  0  1  0  0]\n",
            " [ 0  0  1  9  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  2  0  0  1  3]\n",
            " [ 0  0  0  0  1  0  9  0  0  0]\n",
            " [ 0  0  2  1  0  0  0 11  0  1]\n",
            " [ 0  0  0  0  0  1  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  1  1  2  7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       0.67      0.75      0.71         8\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       0.50      0.29      0.36         7\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       0.85      0.73      0.79        15\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.58      0.64      0.61        11\n",
            "\n",
            "    accuracy                           0.79       100\n",
            "   macro avg       0.72      0.71      0.71       100\n",
            "weighted avg       0.80      0.79      0.79       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a4z5Ya61ddf"
      },
      "source": [
        "**Wniosek**: Używanie funkcji \"deskew\" na obrazach przed zastosowaniem deskryptora HOG zwiększa wynik modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ybVkQjIx74B"
      },
      "source": [
        "# Zadanie 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY5xFMpiyCHR"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c37jIbjU0BO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cc5511-19fd-4fb9-dd87-42a58b85bb9a"
      },
      "source": [
        "# A\n",
        "grid_search_svc(deskewed_hogdata_train, train_labels, deskewed_hogdata_test, test_labels)\n",
        "\n",
        "# B\n",
        "grid_search_svc(deskewed_reshape_train, train_labels, deskewed_reshape_test, test_labels)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier:  SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='sigmoid',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Chosing params:  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
            "97.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  7  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 13  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  0  0  0  0  1 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      1.00      1.00         7\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.87      0.93        15\n",
            "           8       0.67      1.00      0.80         2\n",
            "           9       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.95      0.98      0.96       100\n",
            "weighted avg       0.97      0.97      0.97       100\n",
            "\n",
            "Best classifier:  SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Chosing params:  {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
            "90.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  7  0  0  0  1  0  0  0]\n",
            " [ 0  0  0 10  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  5  0  1  0  0]\n",
            " [ 0  0  2  0  0  0  8  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 13  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  1  0  0  1  0  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.78      0.88      0.82         8\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       0.83      0.71      0.77         7\n",
            "           6       0.89      0.80      0.84        10\n",
            "           7       0.87      0.87      0.87        15\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       0.90      0.82      0.86        11\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.90      0.90      0.90       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoN2PoPcyEMc"
      },
      "source": [
        "RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOW7E8Nz0Bx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3453e4e4-d3c7-4baf-fa57-86eeba55eb51"
      },
      "source": [
        "# A\n",
        "grid_search_rfn(deskewed_hogdata_train, train_labels, deskewed_hogdata_test, test_labels)\n",
        "\n",
        "# B\n",
        "grid_search_rfn(deskewed_reshape_train, train_labels, deskewed_reshape_test, test_labels)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=15, max_features=40,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Chosing params:  {'max_depth': 15, 'max_features': 40, 'n_estimators': 50}\n",
            "93.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  7  0  0  0  0  0  0  0]\n",
            " [ 0  0  1 10  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  7  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  9  0  0  0]\n",
            " [ 0  0  1  1  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  1]\n",
            " [ 1  0  0  0  0  0  0  0  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       0.78      0.88      0.82         8\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         7\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.87      0.93        15\n",
            "           8       1.00      0.50      0.67         2\n",
            "           9       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.93       100\n",
            "   macro avg       0.94      0.90      0.91       100\n",
            "weighted avg       0.93      0.93      0.93       100\n",
            "\n",
            "Best classifier:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=15, max_features=40,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Chosing params:  {'max_depth': 15, 'max_features': 40, 'n_estimators': 120}\n",
            "88.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  9  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  1  0  1  5  0  0  0  0]\n",
            " [ 0  0  3  0  1  0  6  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 15  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  2  0  0  1  0  8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.57      1.00      0.73         8\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       0.78      1.00      0.88        14\n",
            "           5       0.83      0.71      0.77         7\n",
            "           6       1.00      0.60      0.75        10\n",
            "           7       0.94      1.00      0.97        15\n",
            "           8       1.00      0.50      0.67         2\n",
            "           9       1.00      0.73      0.84        11\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.91      0.84      0.85       100\n",
            "weighted avg       0.91      0.88      0.88       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMgpN_mUyEVR"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pamlRJqR0CNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed15363c-8a1a-4c8a-b8d1-332e3843bd6e"
      },
      "source": [
        "# A\n",
        "grid_search_nn(deskewed_hogdata_train, train_labels, deskewed_hogdata_test, test_labels,81)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 1ms/step - loss: 2.3018 - accuracy: 0.1241\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2915 - accuracy: 0.1423\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2897 - accuracy: 0.1356\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2769 - accuracy: 0.1334\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2776 - accuracy: 0.1135\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2674 - accuracy: 0.1248\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2518 - accuracy: 0.1286\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2426 - accuracy: 0.1768\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2252 - accuracy: 0.1873\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1958 - accuracy: 0.1926\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1669 - accuracy: 0.2680\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.1271 - accuracy: 0.2808\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0968 - accuracy: 0.3270\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0721 - accuracy: 0.2928\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0872 - accuracy: 0.3361\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0064 - accuracy: 0.3427\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9556 - accuracy: 0.4019\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9244 - accuracy: 0.4065\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9179 - accuracy: 0.4506\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8594 - accuracy: 0.4823\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8352 - accuracy: 0.4858\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.8002 - accuracy: 0.5536\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7551 - accuracy: 0.5665\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7177 - accuracy: 0.5242\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7007 - accuracy: 0.5753\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7335 - accuracy: 0.5578\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6597 - accuracy: 0.5890\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6231 - accuracy: 0.5473\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6267 - accuracy: 0.5807\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6284 - accuracy: 0.5679\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.5848 - accuracy: 0.5846\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5579 - accuracy: 0.6105\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5074 - accuracy: 0.6348\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4778 - accuracy: 0.6194\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4315 - accuracy: 0.6454\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4329 - accuracy: 0.6284\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4290 - accuracy: 0.6369\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3733 - accuracy: 0.6590\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4152 - accuracy: 0.6272\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3834 - accuracy: 0.6629\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3379 - accuracy: 0.6786\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3283 - accuracy: 0.6646\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3211 - accuracy: 0.6737\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2785 - accuracy: 0.6999\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2708 - accuracy: 0.7363\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2621 - accuracy: 0.7152\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2567 - accuracy: 0.7050\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2200 - accuracy: 0.7192\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2114 - accuracy: 0.7255\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2171 - accuracy: 0.7224\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1867 - accuracy: 0.7434\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1444 - accuracy: 0.7468\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1284 - accuracy: 0.7240\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1797 - accuracy: 0.7459\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0737 - accuracy: 0.7465\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1273 - accuracy: 0.7388\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0909 - accuracy: 0.7617\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0745 - accuracy: 0.7590\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0485 - accuracy: 0.7690\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0085 - accuracy: 0.7913\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0067 - accuracy: 0.7857\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0440 - accuracy: 0.7637\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9834 - accuracy: 0.7611\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.7933\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9630 - accuracy: 0.7942\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9613 - accuracy: 0.8043\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9774 - accuracy: 0.7851\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9440 - accuracy: 0.8020\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8902 - accuracy: 0.8165\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.7858\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8969 - accuracy: 0.7889\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.7865\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8301 - accuracy: 0.8180\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8766 - accuracy: 0.8091\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8687 - accuracy: 0.7947\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7766 - accuracy: 0.8302\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.8221\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8160 - accuracy: 0.7746\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8328 - accuracy: 0.7807\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7885 - accuracy: 0.8257\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7740 - accuracy: 0.8443\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7615 - accuracy: 0.8187\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7952 - accuracy: 0.8217\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.8272\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.8334\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7583 - accuracy: 0.8175\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7407 - accuracy: 0.8476\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.8350\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.8393\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.8319\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.8436\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.8774\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.8444\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.8503\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.8665\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.8297\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.8212\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.8515\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.8500\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.8161\n",
            "Best classifier:  <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f73f243df90>\n",
            "Chosing params:  {'batch_size': 10, 'epochs': 100, 'input_shape': 81}\n",
            "88.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  6  1  0  0  0  1  0  0]\n",
            " [ 0  0  1  9  0  0  0  0  1  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  6  0  0  0  1]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  1  1  0  0  0 12  0  1]\n",
            " [ 0  0  0  0  0  1  0  0  0  1]\n",
            " [ 0  0  0  0  1  0  0  1  0  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.75      0.75      0.75         8\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       0.86      0.86      0.86         7\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.86      0.80      0.83        15\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.75      0.82      0.78        11\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.80      0.80      0.80       100\n",
            "weighted avg       0.87      0.88      0.88       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cModJQwGW-xm",
        "outputId": "14ea65c8-f8d8-4c9c-d669-70dc3d550e7c"
      },
      "source": [
        "# B\n",
        "grid_search_nn(deskewed_reshape_train, train_labels, deskewed_reshape_test, test_labels, 28*28)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 6ms/step - loss: 1.1345 - accuracy: 0.6540\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2459 - accuracy: 0.9408\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.1405 - accuracy: 0.9693\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9788\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9957\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9949\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9928\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9997\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Best classifier:  <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f73f47b1b10>\n",
            "Chosing params:  {'batch_size': 10, 'epochs': 10, 'input_shape': 784}\n",
            "94.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  8  0  3  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  6  0  1  0  0]\n",
            " [ 0  0  1  0  0  0  9  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 15  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  0  0  0  1  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.89      1.00      0.94         8\n",
            "           3       1.00      0.73      0.84        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       0.67      0.86      0.75         7\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       0.88      1.00      0.94        15\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.94       100\n",
            "   macro avg       0.94      0.94      0.94       100\n",
            "weighted avg       0.95      0.94      0.94       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MePPl9Z71o0k"
      },
      "source": [
        "**Wniosek**: Wyniki klasyfikatorów trenowanych danymi po zadziałaniu na nich funkcją OpenCVHOG uzyskują lepsze rezultaty niż klasyfikatorów trenowanych danymi po wyprostowaniu i spłaszczonymi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5K8jwXXyAPr"
      },
      "source": [
        "# Zadanie 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_WfU3DyJCf"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVbq6eQ50Wbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32775bc-6e86-4979-9bf4-5241f148ec21"
      },
      "source": [
        "# A\n",
        "grid_search_svc(deskewed_reshape_train, train_labels, deskewed_reshape_test, test_labels)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier:  SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Chosing params:  {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
            "90.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  7  0  0  0  1  0  0  0]\n",
            " [ 0  0  0 10  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  5  0  1  0  0]\n",
            " [ 0  0  2  0  0  0  8  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 13  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  1  0  0  1  0  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.78      0.88      0.82         8\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       0.83      0.71      0.77         7\n",
            "           6       0.89      0.80      0.84        10\n",
            "           7       0.87      0.87      0.87        15\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       0.90      0.82      0.86        11\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.90      0.90      0.90       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n",
            "Best classifier:  SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Chosing params:  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "14.0\n",
            "[[ 0  8  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0]\n",
            " [ 0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  7  0  0  0  0  0  0  0  0]\n",
            " [ 0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0 15  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0 11  0  0  0  0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         8\n",
            "           1       0.14      1.00      0.25        14\n",
            "           2       0.00      0.00      0.00         8\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.00      0.00      0.00        14\n",
            "           5       0.00      0.00      0.00         7\n",
            "           6       0.00      0.00      0.00        10\n",
            "           7       0.00      0.00      0.00        15\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.14       100\n",
            "   macro avg       0.01      0.10      0.02       100\n",
            "weighted avg       0.02      0.14      0.03       100\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOZFZtv8flff"
      },
      "source": [
        "# B\n",
        "grid_search_svc(deskewed_reshape_shuffle_train, train_labels, deskewed_reshape_shuffle_test, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEuR6K79yJI2"
      },
      "source": [
        "RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD9ungev0XEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94bde8f-6947-4fad-ec87-2dbd7a6a118f"
      },
      "source": [
        "# A\n",
        "grid_search_rfn(deskewed_reshape_train, train_labels, deskewed_reshape_test, test_labels)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=15, max_features=40,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Chosing params:  {'max_depth': 15, 'max_features': 40, 'n_estimators': 120}\n",
            "88.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  1  1  9  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 13  0  0  0  0  1]\n",
            " [ 0  0  1  0  1  5  0  0  0  0]\n",
            " [ 1  0  2  0  0  0  7  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  1]\n",
            " [ 0  0  1  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  1  0  0  1  0  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       0.62      1.00      0.76         8\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       0.87      0.93      0.90        14\n",
            "           5       1.00      0.71      0.83         7\n",
            "           6       1.00      0.70      0.82        10\n",
            "           7       0.93      0.93      0.93        15\n",
            "           8       1.00      0.50      0.67         2\n",
            "           9       0.82      0.82      0.82        11\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.91      0.84      0.85       100\n",
            "weighted avg       0.90      0.88      0.88       100\n",
            "\n",
            "Best classifier:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=10, max_features=40,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Chosing params:  {'max_depth': 10, 'max_features': 40, 'n_estimators': 50}\n",
            "11.0\n",
            "[[1 2 0 1 3 0 0 0 1 0]\n",
            " [1 4 2 1 0 0 1 2 1 2]\n",
            " [0 2 1 1 1 1 0 2 0 0]\n",
            " [1 3 1 0 2 0 0 1 1 2]\n",
            " [0 0 3 1 2 0 2 1 2 3]\n",
            " [0 1 2 1 0 0 1 1 0 1]\n",
            " [0 3 1 0 1 2 0 1 1 1]\n",
            " [2 3 1 0 0 3 3 1 1 1]\n",
            " [0 1 0 0 0 0 0 0 1 0]\n",
            " [0 3 2 1 2 0 0 1 1 1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.12      0.15         8\n",
            "           1       0.18      0.29      0.22        14\n",
            "           2       0.08      0.12      0.10         8\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.18      0.14      0.16        14\n",
            "           5       0.00      0.00      0.00         7\n",
            "           6       0.00      0.00      0.00        10\n",
            "           7       0.10      0.07      0.08        15\n",
            "           8       0.11      0.50      0.18         2\n",
            "           9       0.09      0.09      0.09        11\n",
            "\n",
            "    accuracy                           0.11       100\n",
            "   macro avg       0.09      0.13      0.10       100\n",
            "weighted avg       0.10      0.11      0.10       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_aVa3PfoTi"
      },
      "source": [
        "# B\n",
        "grid_search_rfn(deskewed_reshape_shuffle_train, train_labels, deskewed_reshape_shuffle_test, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7jfPH3yJQn"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZyi1EY0XiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907b66b6-dd3d-494e-9c4c-336d2f2502ab"
      },
      "source": [
        "# A\n",
        "grid_search_nn(deskewed_reshape_train, train_labels, deskewed_reshape_test, test_labels, 28*28)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6765 - accuracy: 0.4453\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5280 - accuracy: 0.8983\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3814 - accuracy: 0.9182\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2603 - accuracy: 0.9543\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2018 - accuracy: 0.9543\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1816 - accuracy: 0.9664\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1457 - accuracy: 0.9766\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1036 - accuracy: 0.9776\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 0.9859\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 0.9885\n",
            "Best classifier:  <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7402865d90>\n",
            "Chosing params:  {'batch_size': 100, 'epochs': 10, 'input_shape': 784}\n",
            "91.0\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  9  0  2  0  0  0  0]\n",
            " [ 0  0  0  0 12  0  1  0  0  1]\n",
            " [ 0  0  0  0  1  5  0  1  0  0]\n",
            " [ 0  0  1  0  0  0  9  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  0  0  0  1  0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.89      1.00      0.94         8\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       0.92      0.86      0.89        14\n",
            "           5       0.71      0.71      0.71         7\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       0.88      0.93      0.90        15\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       0.83      0.91      0.87        11\n",
            "\n",
            "    accuracy                           0.91       100\n",
            "   macro avg       0.91      0.91      0.91       100\n",
            "weighted avg       0.91      0.91      0.91       100\n",
            "\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 1s 5ms/step - loss: 2.5153 - accuracy: 0.1043\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1682 - accuracy: 0.2025\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.0605 - accuracy: 0.2445\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.8595 - accuracy: 0.3633\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.7704 - accuracy: 0.3961\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.6422 - accuracy: 0.4524\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.4647 - accuracy: 0.5262\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2981 - accuracy: 0.6064\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2430 - accuracy: 0.6329\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1403 - accuracy: 0.6824\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9887 - accuracy: 0.7412\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9285 - accuracy: 0.7778\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.8269 - accuracy: 0.7912\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.7171 - accuracy: 0.8177\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.8607\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.5825 - accuracy: 0.8636\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.8617\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.8917\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8905\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8799\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.9087\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3117 - accuracy: 0.9171\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.9274\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2569 - accuracy: 0.9282\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2643 - accuracy: 0.9244\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9424\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9512\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2517 - accuracy: 0.9213\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1968 - accuracy: 0.9594\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9743\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1844 - accuracy: 0.9442\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9554\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9576\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9382\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9722\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9803\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9726\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9772\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9687\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9774\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9738\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9874\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9823\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9783\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9910\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9844\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9798\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9881\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9939\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9905\n",
            "Best classifier:  <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f73fbe014d0>\n",
            "Chosing params:  {'batch_size': 10, 'epochs': 50, 'input_shape': 784}\n",
            "13.0\n",
            "[[2 3 3 0 0 0 0 0 0 0]\n",
            " [2 1 3 3 2 0 1 2 0 0]\n",
            " [0 2 0 1 1 1 1 2 0 0]\n",
            " [1 0 2 1 1 2 2 1 1 0]\n",
            " [5 2 4 1 0 1 0 0 0 1]\n",
            " [0 2 2 1 0 0 0 0 1 1]\n",
            " [1 1 3 1 1 0 0 3 0 0]\n",
            " [0 0 2 1 0 1 3 6 0 2]\n",
            " [1 0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 1 2 0 1 2 1 3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.25      0.19         8\n",
            "           1       0.09      0.07      0.08        14\n",
            "           2       0.00      0.00      0.00         8\n",
            "           3       0.10      0.09      0.10        11\n",
            "           4       0.00      0.00      0.00        14\n",
            "           5       0.00      0.00      0.00         7\n",
            "           6       0.00      0.00      0.00        10\n",
            "           7       0.35      0.40      0.38        15\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.43      0.27      0.33        11\n",
            "\n",
            "    accuracy                           0.13       100\n",
            "   macro avg       0.11      0.11      0.11       100\n",
            "weighted avg       0.14      0.13      0.13       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCEUn0zufqO2"
      },
      "source": [
        "# B\n",
        "grid_search_nn(deskewed_reshape_shuffle_train, train_labels, deskewed_reshape_shuffle_test, test_labels, 28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbf7Xpn1sZw"
      },
      "source": [
        "**Wniosek**: Wyniki dla klasyfikatorów, na których wejściu podaje się dane \"zmieszane\" są znacznie gorsze niż wyniki dla klasyfikatorów, na których wejściu podaje się dane spłaszczone."
      ]
    }
  ]
}